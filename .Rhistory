# Load the Caret library to use the data within
library("caret") # contains 'diamonds' data to be used, and 'train' function used to create folds
library("MASS")  # Contains data on Boston homes to use as practice
# Creating the folds and model to be used for diamond data
set.seed(29)
model_dia <- train(price ~ ., diamonds, # Train the model with the diamonds data set and use price as the output
method = "lm", #linear model
trControl = trainControl(method = "cv",      # Resampling method
number = 10,        # Number of folds
verboseIter = FALSE # verboseIter determines if the train function prints its iterations
)
)
# Using the model to predict the price of diamonds
p_dia <- predict(model_dia, diamonds)
error_dia <- p_dia - diamonds$price
rmse_xval_dia <- sqrt(mean(error_dia^2)) # Cross validated RMSE
rmse_xval_dia
# Creating the folds and model to be used for Boston home data
set.seed(29)
model_Bos <- train(medv ~ ., Boston, # Train the model with the diamonds data set and use price as the output
method = "lm", #linear model
trControl = trainControl(method = "cv",      # Resampling method
number = 10,        # Number of folds
verboseIter = FALSE # verboseIter determines if the train function prints its iterations
)
)
# Using the model to predict the price of diamonds
p_Bos <- predict(model_Bos, Boston)
error_Bos <- p_Bos- Boston$medv
rmse_xval_Bos <- sqrt(mean(error_Bos^2)) # Cross validated RMSE
rmse_xval_Bos
?sample
?glm
Sonar
data(Sonar)
library("mlbench")
install.package("mlbench")
install.packages("mlbench")
library("mlbench")
install.packages("mlbench")
install.packages("mlbench") # Need to install Rtools42 for this package to install correctly, following an update to R
install.packages("mlbench") # Need to install Rtools42 for this package to install correctly, following an update to R
# Rtools42 install link: https://cran.rstudio.com/bin/windows/Rtools/rtools42/rtools.html
library("mlbench") # Contains the Sonar dataset used in this model
install.packages("mlbench") # Need to install Rtools42 for this package to install correctly, following an update to R
# Rtools42 install link: https://cran.rstudio.com/bin/windows/Rtools/rtools42/rtools.html
library("mlbench") # Contains the Sonar dataset used in this model
data(Sonar)
# Rtools42 install link: https://cran.rstudio.com/bin/windows/Rtools/rtools42/rtools.html
library("mlbench") # Contains the Sonar dataset used in this model
data(Sonar)
# 60/40 split
tr_perc <- 0.6
tr <- sample(nrow(Sonar), # take from the Sonar set
round(nrow(Sonar)*tr_perc)) # Take 60% of rows from the Sonar set
train <- Sonar[tr,] # Define the training set as the rows from sonar
test <- Sonar[-tr,] # Define the test set as all rows not in the training set
model <- glm(Class ~ ., # Generalized linear model,
data = train,
family = "binomial")
?help
?predict
?type
?response
# Rtools42 install link: https://cran.rstudio.com/bin/windows/Rtools/rtools42/rtools.html
library("mlbench") # Contains the Sonar dataset used in this model
data(Sonar)
# 60/40 split
tr_perc <- 0.6
tr <- sample(nrow(Sonar), # take from the Sonar set
round(nrow(Sonar)*tr_perc)) # Take 60% of rows from the Sonar set
train <- Sonar[tr,] # Define the training set as the rows from sonar
test <- Sonar[-tr,] # Define the test set as all rows not in the training set
model <- glm(Class ~ ., # Generalized linear model,
data = train,
family = "binomial")
p <- predict(model, # Use model to predict
test,  # Use test to determine the accuracy
type = "response") # Gives the output as the predicted probabilities
summary(p)
View(test)
View(Sonar)
summary(p)
# Return results as a table
cl <- ifelse(p > 0.5, "Mine", "Rock") # Sort the categories into "Mine" or "Rock" based on if they're greater or less than 0.5
table(cl,test$Class)
data(Sonar)
# 60/40 split
tr_perc <- 0.6
tr <- sample(nrow(Sonar), # take from the Sonar set
round(nrow(Sonar)*tr_perc)) # Take 60% of rows from the Sonar set
train <- Sonar[tr,] # Define the training set as the rows from sonar
test <- Sonar[-tr,] # Define the test set as all rows not in the training set
model <- glm(Class ~ ., # Generalized linear model,
data = train,
family = "binomial")
p <- predict(model, # Use model to predict
test,  # Use test to determine the accuracy
type = "response") # Gives the output as the predicted probabilities
summary(p)
# Return results as a table
cl <- ifelse(p > 0.5, "Mine", "Rock") # Sort the categories into "Mine" or "Rock" based on if they're greater or less than 0.5
table(cl,test$Class)
?Sonar
library("carat")
library("caret")
# Using the carat package to get more information on the accuracy of this model
confusionMatrix(factor(cl), test$Class)
?confusionMatrix
?factor
# Rtools42 install link: https://cran.rstudio.com/bin/windows/Rtools/rtools42/rtools.html
library("mlbench") # Contains the Sonar dataset used in this model
library("caret") # Contains a single line function to create a confusion matrix
data(Sonar)
# 60/40 split
tr_perc <- 0.6
tr <- sample(nrow(Sonar), # take from the Sonar set
round(nrow(Sonar)*tr_perc)) # Take 60% of rows from the Sonar set
train <- Sonar[tr,] # Define the training set as the rows from sonar
test <- Sonar[-tr,] # Define the test set as all rows not in the training set
model <- glm(Class ~ ., # Generalized linear model,
data = train,
family = "binomial")
p <- predict(model, # Use model to predict
test,  # Use test to determine the accuracy
type = "response") # Gives the output as the predicted probabilities
summary(p)
# Return results as a table
cl <- ifelse(p > 0.5, "M", "R") # Sort the categories into "M" for mine or "R" for rock based on if they're greater or less than 0.5
table(cl,test$Class) # Horizontal are assignments that the model made, vertical are the real assignments made
# Using the carat package to get more information on the accuracy of this model
confusionMatrix(factor(cl), # The data
test$Class) # The reference
# Return results as a table
cl <- ifelse(p > 0.9, "M", "R") # Sort the categories into "M" for mine or "R" for rock based on if they're greater or less than 0.5
table(cl,test$Class) # Horizontal are assignments that the model made, vertical are the real assignments made
# Using the carat package to get more information on the accuracy of this model
confusionMatrix(factor(cl), # The data
test$Class) # The reference
# Return results as a table
cl <- ifelse(p > 0.1, "M", "R") # Sort the categories into "M" for mine or "R" for rock based on if they're greater or less than 0.5
table(cl,test$Class) # Horizontal are assignments that the model made, vertical are the real assignments made
# Using the carat package to get more information on the accuracy of this model
confusionMatrix(factor(cl), # The data
test$Class) # The reference
?rpart
library("rpart") # Recursive partitioning package
library("rpart.plot") # Plotting recursive partioning package
install.packages("rpart.plot")
library("rpart.plot") # Plotting recursive partioning package
library("rpart.plot") # Plotting recursive partioning package
install.packages("rpart.plot")
library("rpart.plot") # Plotting recursive partioning package
install.packages("rpart.plot")
install.packages("rpart.plot")
install.packages("rpart.plot")
library("rpart") # Recursive partitioning package
library("rpart.plot") # Plotting recursive partioning package
library("rpart.plot") # Plotting recursive partioning package
install.packages("rpart.plot")
?install.packages
install.packages("rpart.plot", dependancies = TRUE)
install.packages("rpart.plot", dependancies = TRUE)
library("rpart") # Recursive partitioning package
library("rpart.plot") # Plotting recursive partioning package
# Plotting the first decision tree randomly made
m <- rpart(Class ~ ., data = Sonar,
method = "class")
?Sonar
library("mlbench") # Sonar data being used
# Plotting the first decision tree randomly made
m <- rpart(Class ~ ., data = Sonar,
method = "class")
# Plotting the first decision tree randomly made
data(Sonar)
m <- rpart(Class ~ ., data = Sonar,
method = "class")
rpart.plot(m)
p <- predict(m, Sonar, type = "class")
table(p, Sonar$Class)
?train
library("rpart") # Recursive partitioning package
library("rpart.plot") # Plotting recursive partioning package
library("mlbench") # Sonar data being used
library("caret") # Contains the train function
# Plotting the first decision tree randomly made
data(Sonar)
set.seed(12) # Used in practice to judge results and how they relate to the method given
model <- train(Class ~ .,
data = Sonar,
method = "ranger") # Random forest method to create a model
set.seed(12) # Used in practice to judge results and how they relate to the method given
model <- train(Class ~ .,
data = Sonar,
method = "ranger") # Random forest method to create a model
print(model)
plot(model)
model <- train(Class ~ .,
data = Sonar,
method = "ranger", # Random forest method to create a model
tuneLength = 5 # Sets number of hyperparameter values to test
)
print(model)
plot(model)
?expand.grid
?mtry
??mtry
??trControl
?train
library("rpart") # Recursive partitioning package
library("rpart.plot") # Plotting recursive partioning package
library("mlbench") # Sonar data being used
library("caret") # Contains the train function
# Plotting the first decision tree randomly made
data(Sonar)
set.seed(42) # Used in practice to judge results and how they relate to the method given by tutorial
# Create a grid to use when creating the model
my_grid <- expand.grid(mtry = c(5, 10, 20, 40, 60), # Create a data frame, and define the number of variable randomly collected to sample for each split
splitrule = c("gini", "extratrees"), # Extratrees is a splitting rule for the decision trees that splits the nodes by choosing cut-points fully at random, and gini is a splitting rule that looks at the probability the model is wrong
min.node.size = 1 # Default is 1 for classification
)
# Create a grid to use when creating the model
my_grid <- expand.grid(mtry = c(5, 10, 20, 40, 60), # Create a data frame, and define the number of variable randomly collected to sample for each split
splitrule = c("gini", "extratrees"), # Extratrees is a splitting rule for the decision trees that splits the nodes by choosing cut-points fully at random, and gini is a splitting rule that looks at the probability the model is wrong
min.node.size = 1 # Default is 1 for classification
)
library("rpart") # Recursive partitioning package
library("rpart.plot") # Plotting recursive partioning package
library("mlbench") # Sonar data being used
library("caret") # Contains the train function
# Plotting the first decision tree randomly made
data(Sonar)
set.seed(42) # Used in practice to judge results and how they relate to the method given by tutorial
# Create a grid to use when creating the model
my_grid <- expand.grid(mtry = c(5, 10, 20, 40, 60), # Create a data frame, and define the number of variable randomly collected to sample for each split
splitrule = c("gini", "extratrees"), # Extratrees is a splitting rule for the decision trees that splits the nodes by choosing cut-points fully at random, and gini is a splitting rule that looks at the probability the model is wrong
min.node.size = 1 # Default is 1 for classification
)
View(my_grid)
# Create the model used
model <- train(Class ~ .,
data = Sonar,
method = "ranger", # Random forest method to create a model
tuneGrid = myGrid,
trControl = trainControl(method = "cv", # Resampling method; cross validation
number = 5, # Number of folds for cross validation
verboseIter = FALSE # Won't print the training log
)
# tuneLength = 5 # Sets number of hyperparameter values to test; commented out for practice elsewhere
)
# Create the model used
model <- train(Class ~ .,
data = Sonar,
method = "ranger", # Random forest method to create a model
tuneGrid = my_grid,
trControl = trainControl(method = "cv", # Resampling method; cross validation
number = 5, # Number of folds for cross validation
verboseIter = FALSE # Won't print the training log
)
# tuneLength = 5 # Sets number of hyperparameter values to test; commented out for practice elsewhere
)
print(model) # Provide information about the model
plot(model) # Graphically represent the model's accuracy
# Create the model used
model <- train(Class ~ .,
data = Sonar,
method = "ranger", # Random forest method to create a model
tuneGrid = my_grid,
trControl = trainControl(method = "cv", # Resampling method; cross validation
number = 5, # Number of folds for cross validation
verboseIter = FALSE # Won't print the training log
)
tuneLength = 5 # Sets number of hyperparameter values to test; commented out for practice elsewhere
# Create the model used
model <- train(Class ~ .,
data = Sonar,
method = "ranger", # Random forest method to create a model
tuneGrid = my_grid,
trControl = trainControl(method = "cv", # Resampling method; cross validation
number = 5, # Number of folds for cross validation
verboseIter = FALSE # Won't print the training log
),
tuneLength = 5 # Sets number of hyperparameter values to test; commented out for practice elsewhere
)
print(model) # Provide information about the model
plot(model) # Graphically represent the model's accuracy
