data(iris)
library(class)
data(iris)
library("class")
data(iris)
set.seed(12L)
tr <- sample (150,50)
nw <- sample (150,50)
?set.seed
set.seed(12L)
library("class")
# Drawing 50 random iris observations to train the knn ML model
set.seed(12L)
tr <- sample (150,50)
nw <- sample (150,50)
knnres <- knn()
?set.seed
?sample
?knnres
?head
library("class") # Package containing knn function to develop k Nearest Neighbor machine learning model
# Drawing 50 random iris observations to train the knn ML model
set.seed(12L) # Specifies a seed
tr <- sample (150,50) # Creates training set of 50 points of data
nw <- sample (150,50) # Creates new set of data to determine accuracy of ML model
knnResult <- knn(iris[tr, -5], iris[nw,-5], iris$Species[tr]) # Runs the ML model
head(knnResult) # See the first and last parts of the df for the knn
?knn
# Compare observed knn product to the observed outcome
table(knnResults, iris$Species[nw])
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw])
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw])
acc <- mean(knnResult == iris$Species[nw])
acc
?table
gc()
library("class") # Package containing knn function to develop k Nearest Neighbor machine learning model
# Drawing 50 random iris observations to train the knn ML model
tr <- sample (150,50) # Creates training set of 50 points of data
nw <- sample (150,50) # Creates new set of data to determine accuracy of ML model
# Drawing 50 random iris observations to train the knn ML model
tr <- sample (150,50) # Creates training set of 50 points of data
nw <- sample (150,50) # Creates new set of data to determine accuracy of ML model
knnResult <- knn(iris[tr, -5], # Assigns training data
iris[nw,-5],  # Assigns testing data
iris$Species[tr] # Assigns response variables
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
acc <- mean(knnResult == iris$Species[nw])
acc
?knn
# Drawing 50 random iris observations to train the knn ML model
set.seed(12L) # Specifies a seed
tr <- sample (150,50) # Creates training set of 50 points of data
nw <- sample (150,50) # Creates new set of data to determine accuracy of ML model
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=2               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
acc <- mean(knnResult == iris$Species[nw])
acc
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=1               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
acc <- mean(knnResult == iris$Species[nw])
acc
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=1               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK1 <- mean(knnResult == iris$Species[nw])
accK1
# Drawing 50 random iris observations to train the knn ML model
set.seed(12L) # Specifies a seed
tr <- sample (150,50) # Creates training set of 50 points of data
nw <- sample (150,50) # Creates new set of data to determine accuracy of ML model
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=1               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK1 <- mean(knnResult == iris$Species[nw])
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=2               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK1 <- mean(knnResult == iris$Species[nw])
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=1               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK1 <- mean(knnResult == iris$Species[nw])
accK1
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=2               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK2 <- mean(knnResult == iris$Species[nw])
accK1
accK2
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=3               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK3 <- mean(knnResult == iris$Species[nw]) # Modified to check different values of k
accK1 # accuracy when k = 1
accK2 # accuracy when k = 2
acck3 # accuracy when k = 3
acck3 # accuracy when k = 3
accK3 <- mean(knnResult == iris$Species[nw]) # Modified to check different values of k
accK1 # accuracy when k = 1
accK2 # accuracy when k = 2
acck3 # accuracy when k = 3
accK3 # accuracy when k = 3
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=4               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK4 <- mean(knnResult == iris$Species[nw]) # Modified to check different values of k
accK1 # accuracy when k = 1
accK2 # accuracy when k = 2
accK3 # accuracy when k = 3
accK4 # accuracy when k = 4
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=5               # Assigns number of neighbors to check
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK5 <- mean(knnResult == iris$Species[nw]) # Modified to check different values of k
accK1 # accuracy when k = 1; 0.96 for the above seed
accK2 # accuracy when k = 2; 0.94 for the above seed
accK3 # accuracy when k = 3; 0.94 for the above seed
accK4 # accuracy when k = 4; 0.96 for the above seed
accK5 # accuracy when k = 5;
knnResult <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=5,              # Assigns number of neighbors to check
prob = TRUE
) # Runs the ML model
head(knnResult) # See the first part of the factor after running the knn function
# Compare observed knn product to the observed outcome
table(knnResult, iris$Species[nw]) # Compares the Species printed by the knn function to the expected species
accK5 <- mean(knnResult == iris$Species[nw]) # Modified to check different values of k
accK1 # accuracy when k = 1; 0.96 for the above seed
accK2 # accuracy when k = 2; 0.94 for the above seed
accK3 # accuracy when k = 3; 0.94 for the above seed
accK4 # accuracy when k = 4; 0.96 for the above seed
accK5 # accuracy when k = 5; 0.94 for the above seed
knnResult5Prob <- knn(iris[tr, -5],     # Assigns training data
iris[nw,-5],      # Assigns testing data
iris$Species[tr], # Assigns response variables
k=5,              # Assigns number of neighbors to check
prob = TRUE
) # Runs the ML model
head(knnResult5Prob) # See the first part of the factor after running the knn function
# Checking what happens with 'prob = true'
table(attr(knnResult5Prob, "prob"))
?attr
?lm
?data
?lm
?~
help
?.
??.
?lm
?predict
data(diamonds) # loads the data set
# Load the Caret library to use the data within
library("caret")
data(diamonds) # loads the data set
model <- lm(price ~ ., diamonds) # Linear model where "price ~ ." is the formula
p <- predict(model, diamonds) # Generic prediction for model fitting functions
# Load the Caret library to use the data within
library("caret")
data(diamonds) # loads the data set
model <- lm(price ~ ., diamonds) # Linear model where "price ~ ." is the formula
p <- predict(model, diamonds) # Generic prediction for model fitting functions
# In-sample error on prediction
error <- p - diamonds$price
rmse_in <- sqrt(mean(error^2)) # in-sample RMSE
rmse_in
source("C:/Users/autum/Sites/AuqaMachina/Practicing/regressionPractice.R")
?nrow
# Create out of sample RMSE by removing 20% to serve as testing data
set.seed(29) # Choose a seed to keep same 20% of samples excluded to play with other parameters of model
n_test <- nrow(diamonds) * 0.80 # Pull 80% of rows out for testing
test <- sample(nrow(diamonds), ntest)
?sample
View(diamonds)
?lm
# Load the Caret library to use the data within
library("caret")
data(diamonds) # loads the data set
model1 <- lm(price ~ ., diamonds) # Linear model excluding price from the data examined
# Load the Caret library to use the data within
library("caret")
data(diamonds) # loads the data set
model1 <- lm(price ~ ., diamonds) # Linear model excluding price from the data examined
p1 <- predict(model1, diamonds) # Generic prediction for model fitting functions
# In-sample error on prediction
error1 <- p1 - diamonds$price
rmse_in <- sqrt(mean(error1^2)) # in-sample RMSE
rmse_in
# Create out of sample RMSE by removing 20% to serve as testing data
set.seed(29) # Choose a seed to keep same 20% of samples excluded to play with other parameters of model
n_test <- nrow(diamonds) * 0.80 # Calculate the number for 80% of the rows
test <- sample(nrow(diamonds), n_test) # Create a dataframe with 80% of the rows of diamonds to serve as the testing data
model2 <- lm(price ~ ., data = diamonds[test, ]) # Create a linear model using the same set up as before, but with less training data
p2 <- predict(model2, diamonds[-test, ]) # Predict the price of the testing data based on the linear model
# Calculate out-of-sample RMSE using the 20% for testing
error2 <- p2 - diamonds$price[-test] # calculate the difference in the predicted prices from the actual prices
rmse_out <- sqrt(mean(error2^2))
rmse_out
rmse_in
# Create out of sample RMSE by removing 20% to serve as testing data
set.seed(42) # Choose a seed to keep same 20% of samples excluded to play with other parameters of model
n_test <- nrow(diamonds) * 0.80 # Calculate the number for 80% of the rows
test <- sample(nrow(diamonds), n_test) # Create a dataframe with 80% of the rows of diamonds to serve as the testing data
model2 <- lm(price ~ ., data = diamonds[test, ]) # Create a linear model using the same set up as before, but with less training data
p2 <- predict(model2, diamonds[-test, ]) # Predict the price of the testing data based on the linear model
# Calculate out-of-sample RMSE using the 20% for testing
error2 <- p2 - diamonds$price[-test] # calculate the difference in the predicted prices from the actual prices
rmse_out <- sqrt(mean(error2^2))
rmse_out
rmse_in
per <- 0.80
function (data, expr, ...)
# Load the Caret library to use the data within
library("caret")
data(diamonds) # loads the data set
model1 <- lm(price ~ ., diamonds) # Linear model excluding price from the data examined
p1 <- predict(model1, diamonds) # Generic prediction for model fitting functions
# In-sample error on prediction
error1 <- p1 - diamonds$price
rmse_in <- sqrt(mean(error1^2)) # in-sample RMSE
rmse_in
# Create out of sample RMSE by removing 20% to serve as testing data
set.seed(29) # Choose a seed to keep same 20% of samples excluded to play with other parameters of model
per <- 0.80
n_test <- nrow(diamonds) * per # Calculate the number for [percent]% of the rows
test <- sample(nrow(diamonds), n_test) # Create a dataframe with 80% of the rows of diamonds to serve as the testing data
model2 <- lm(price ~ ., data = diamonds[test, ]) # Create a linear model using the same set up as before, but with less training data
p2 <- predict(model2, diamonds[-test, ]) # Predict the price of the testing data based on the linear model
# Calculate out-of-sample RMSE using the 20% for testing
error2 <- p2 - diamonds$price[-test] # calculate the difference in the predicted prices from the actual prices
rmse_out <- sqrt(mean(error2^2))
rmse_out
rmse_in
# Create out of sample RMSE by removing 20% to serve as testing data
set.seed(29) # Choose a seed to keep same 20% of samples excluded to play with other parameters of model
per <- 0.90
n_test <- nrow(diamonds) * per # Calculate the number for [percent]% of the rows
test <- sample(nrow(diamonds), n_test) # Create a dataframe with 80% of the rows of diamonds to serve as the testing data
model2 <- lm(price ~ ., data = diamonds[test, ]) # Create a linear model using the same set up as before, but with less training data
p2 <- predict(model2, diamonds[-test, ]) # Predict the price of the testing data based on the linear model
# Calculate out-of-sample RMSE using the 20% for testing
error2 <- p2 - diamonds$price[-test] # calculate the difference in the predicted prices from the actual prices
rmse_out <- sqrt(mean(error2^2))
rmse_out
rmse_in
per <- 0.50
# Create out of sample RMSE by removing 20% to serve as testing data
set.seed(29) # Choose a seed to keep same 20% of samples excluded to play with other parameters of model
per <- 0.50
n_test <- nrow(diamonds) * per # Calculate the number for [percent]% of the rows
test <- sample(nrow(diamonds), n_test) # Create a dataframe with 80% of the rows of diamonds to serve as the testing data
model2 <- lm(price ~ ., data = diamonds[test, ]) # Create a linear model using the same set up as before, but with less training data
p2 <- predict(model2, diamonds[-test, ]) # Predict the price of the testing data based on the linear model
# Calculate out-of-sample RMSE using the 20% for testing
error2 <- p2 - diamonds$price[-test] # calculate the difference in the predicted prices from the actual prices
rmse_out <- sqrt(mean(error2^2))
rmse_out
rmse_in
# Create out of sample RMSE by removing 20% to serve as testing data
set.seed(29) # Choose a seed to keep same 20% of samples excluded to play with other parameters of model
per <- 0.95
n_test <- nrow(diamonds) * per # Calculate the number for [percent]% of the rows
test <- sample(nrow(diamonds), n_test) # Create a dataframe with 80% of the rows of diamonds to serve as the testing data
model2 <- lm(price ~ ., data = diamonds[test, ]) # Create a linear model using the same set up as before, but with less training data
p2 <- predict(model2, diamonds[-test, ]) # Predict the price of the testing data based on the linear model
# Calculate out-of-sample RMSE using the 20% for testing
error2 <- p2 - diamonds$price[-test] # calculate the difference in the predicted prices from the actual prices
rmse_out <- sqrt(mean(error2^2))
rmse_out
rmse_in
?trControl
?trainControl
# Load the Caret library to use the data within
library("caret") # contains 'diamonds' data to be used, and 'train' function used to create folds
# Creating the folds and model to be used
set.seed(29)
model <- train(price ~ ., diamonds, # Train the model with the diamonds data set and use price as the output
method = "lm", #linear model
trControl = trainControl(method = "cv",      # Resampling method
number = 10,        # Number of folds
verboseIter = FALSE # verboseIter determines if the train function prints its iterations
)
)
model
model
model
# Using the model to predict the price of diamonds
p <- predict(model, diamonds)
error <- p - diamonds$price
rmse_xval <- sqrt(mean(error^2)) # Cross validated RMSE
rmse_xval
library("MASS") # Contains data on Boston homes to use as practice
Boston
Boston
Bos <- Boston
View(Bos)
# Load the Caret library to use the data within
library("caret") # contains 'diamonds' data to be used, and 'train' function used to create folds
library("MASS")  # Contains data on Boston homes to use as practice
# Creating the folds and model to be used for diamond data
set.seed(29)
model <- train(price ~ ., diamonds, # Train the model with the diamonds data set and use price as the output
method = "lm", #linear model
trControl = trainControl(method = "cv",      # Resampling method
number = 10,        # Number of folds
verboseIter = FALSE # verboseIter determines if the train function prints its iterations
)
)
model
# Using the model to predict the price of diamonds
p_dia <- predict(model, diamonds)
error_dia <- p_dia - diamonds$price
rmse_xval_dia <- sqrt(mean(error_dia^2)) # Cross validated RMSE
rmse_xval_dia
# Creating the folds and model to be used for diamond data
set.seed(29)
model_dia <- train(price ~ ., diamonds, # Train the model with the diamonds data set and use price as the output
method = "lm", #linear model
trControl = trainControl(method = "cv",      # Resampling method
number = 10,        # Number of folds
verboseIter = FALSE # verboseIter determines if the train function prints its iterations
)
)
# Using the model to predict the price of diamonds
p_dia <- predict(model, diamonds)
# Using the model to predict the price of diamonds
p_dia <- predict(model_dia, diamonds)
error_dia <- p_dia - diamonds$price
rmse_xval_dia <- sqrt(mean(error_dia^2)) # Cross validated RMSE
# Using the model to predict the price of diamonds
p_dia <- predict(model_dia, diamonds)
error_dia <- p_dia - diamonds$price
rmse_xval_dia <- sqrt(mean(error_dia^2)) # Cross validated RMSE
rmse_xval_dia
# Creating the folds and model to be used for Boston home data
set.seed(29)
model_Bos <- train(medv ~ ., Boston, # Train the model with the diamonds data set and use price as the output
method = "lm", #linear model
trControl = trainControl(method = "cv",      # Resampling method
number = 10,        # Number of folds
verboseIter = FALSE # verboseIter determines if the train function prints its iterations
)
)
# Using the model to predict the price of diamonds
p_Bos <- predict(model_Bos, Boston)
error_Bos <- p_Bos- Boston$medv
rmse_xval_Bos <- sqrt(mean(error_Bos^2)) # Cross validated RMSE
rmse_xval_Bos
